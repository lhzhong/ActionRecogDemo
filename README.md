# Demo
## 效果

![image](https://github.com/lhzhong/ActionRecogDemo/blob/master/demo.gif)

## 运行环境及安装需求
我的程序是在Ubuntu16.04和装有Tian1080Ti的环境中运行。要运行该demo，需要安装
* python3
* Tensorflow 1.3+
* opencv
* ffmpeg

## 功能
该demo实现的是视频行为的简单识别，视频采集途径包括实施摄像头采集和从本低选取已有视频。

## 细节
1. 界面设计是基于pyqt5的
2. 测试时模型是调取已训练得到的模型，模型训练基于UCF101数据库（训练基于视频单帧的CNN训练，后续需要模型改进）
3. 目前测试是对单帧视频帧进行测试（后续需要进一步的算法完善，实现小段视频的识别识别率更加可靠）
4. 视频读取（摄像头、文件读取）和识别是放在两个线程处理的，视频读取放在主线程，而识别是通过pyqt中的Thread开的新线程，数据处理通过`pyqtSignal`函数进行线程间数据交互
* 多线程互斥锁  
我们为了能让程序在主线程中让子线程暂停，在子线程中设置一个标志，在主线程中更改这个标志，并在子线程的run函数中判断，这里为了保护这个标志，防止多线程中多次调用，我们设置了QMutexLocker。这是线程的互斥锁，通过该锁在我们通过设置标志位来开启或关闭子线程的时候，我们可以保证不受其他线程影响。虽然在我们的项目中，只有两个线程，受影响的可能比较小，但是加上这个有利于程序的完备性。
* 自定义信号
自定义信号的一般流程如下： 
  * 定义信号 
  * 定义槽函数 
  * 绑定信号和槽 
  * 发射信号

在我们的demo中，我们是在子线程中定义信号，我们这个信号只是为了来进行识别，槽函数即是用来预测的函数，在子线程中每隔一定时间来发射信号，触发槽函数进行预测，预测时的数据是通过采集视频帧得到的。然后再将结果显示在界面相应位置。
